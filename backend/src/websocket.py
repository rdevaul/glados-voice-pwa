"""
WebSocket handler for voice streaming API.
Generated by qwen2.5-coder:32b, refined by GLaDOS.
"""

import asyncio
import logging
from typing import Dict, Optional, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from starlette.websockets import WebSocketState

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


# =============================================================================
# Message Types (Client → Server)
# =============================================================================

class AudioStartMessage(BaseModel):
    type: str = "audio_start"
    format: str  # webm, wav, mp4


class AudioEndMessage(BaseModel):
    type: str = "audio_end"


class TextMessage(BaseModel):
    type: str = "text"
    content: str


class CancelMessage(BaseModel):
    type: str = "cancel"


# =============================================================================
# Message Types (Server → Client)
# =============================================================================

class ReadyMessage(BaseModel):
    type: str = "ready"
    session_id: str


class PartialTranscriptMessage(BaseModel):
    type: str = "partial_transcript"
    text: str
    is_final: bool = False


class FinalTranscriptMessage(BaseModel):
    type: str = "final_transcript"
    text: str


class ResponseChunkMessage(BaseModel):
    type: str = "response_chunk"
    text: str
    accumulated: str


class ResponseCompleteMessage(BaseModel):
    type: str = "response_complete"
    text: str
    audio_url: str


class ErrorMessage(BaseModel):
    type: str = "error"
    code: str
    message: str


# =============================================================================
# WebSocket Manager
# =============================================================================

class WebSocketManager:
    """Manages WebSocket connections and message routing."""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.audio_buffers: Dict[str, bytearray] = {}
        self.audio_formats: Dict[str, str] = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        """Accept connection and send ready message."""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        self.audio_buffers[session_id] = bytearray()
        
        ready_message = ReadyMessage(session_id=session_id)
        await websocket.send_json(ready_message.dict())
        logger.info(f"Client connected: {session_id}")

    async def disconnect(self, session_id: str):
        """Clean up connection state."""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
        if session_id in self.audio_buffers:
            del self.audio_buffers[session_id]
        if session_id in self.audio_formats:
            del self.audio_formats[session_id]
        logger.info(f"Client disconnected: {session_id}")

    async def send_message(self, message: BaseModel, session_id: str):
        """Send a message to a specific session."""
        if session_id in self.active_connections:
            ws = self.active_connections[session_id]
            if ws.client_state == WebSocketState.CONNECTED:
                await ws.send_json(message.dict())

    async def handle_json_message(self, websocket: WebSocket, session_id: str, data: Dict[str, Any]):
        """Route JSON messages to appropriate handlers."""
        msg_type = data.get("type")
        
        try:
            if msg_type == "audio_start":
                audio_start = AudioStartMessage(**data)
                self.audio_formats[session_id] = audio_start.format
                self.audio_buffers[session_id] = bytearray()
                logger.debug(f"Audio start: format={audio_start.format}")
                
            elif msg_type == "audio_end":
                logger.debug(f"Audio end: {len(self.audio_buffers.get(session_id, []))} bytes buffered")
                await self._process_audio(session_id)
                
            elif msg_type == "text":
                text_msg = TextMessage(**data)
                logger.debug(f"Text received: {text_msg.content[:50]}...")
                await self._process_text(session_id, text_msg.content)
                
            elif msg_type == "cancel":
                logger.debug(f"Cancel received for {session_id}")
                # TODO: Cancel any in-progress transcription/response
                self.audio_buffers[session_id] = bytearray()
                
            else:
                logger.warning(f"Unknown message type: {msg_type}")
                await self.send_message(
                    ErrorMessage(code="unknown_type", message=f"Unknown message type: {msg_type}"),
                    session_id
                )
                
        except Exception as e:
            logger.exception(f"Error handling message: {e}")
            await self.send_message(
                ErrorMessage(code="message_error", message=str(e)),
                session_id
            )

    async def handle_binary(self, websocket: WebSocket, session_id: str, data: bytes):
        """Buffer incoming audio chunks."""
        if session_id in self.audio_buffers:
            self.audio_buffers[session_id].extend(data)
            logger.debug(f"Audio chunk: {len(data)} bytes (total: {len(self.audio_buffers[session_id])})")
        else:
            logger.warning(f"Received binary data without audio_start for {session_id}")

    async def _process_audio(self, session_id: str):
        """Process buffered audio - transcribe and generate response."""
        audio_data = bytes(self.audio_buffers.get(session_id, b""))
        audio_format = self.audio_formats.get(session_id, "webm")
        
        if not audio_data:
            await self.send_message(
                ErrorMessage(code="no_audio", message="No audio data received"),
                session_id
            )
            return

        logger.info(f"Processing {len(audio_data)} bytes of {audio_format} audio")
        
        # TODO: Implement streaming transcription
        # For now, send placeholder
        await self.send_message(
            PartialTranscriptMessage(text="Processing audio...", is_final=False),
            session_id
        )
        
        # Placeholder - will be replaced with actual transcription
        await self.send_message(
            FinalTranscriptMessage(text="[Transcription placeholder]"),
            session_id
        )
        
        # Placeholder response
        await self.send_message(
            ResponseChunkMessage(text="I received your ", accumulated="I received your "),
            session_id
        )
        await self.send_message(
            ResponseChunkMessage(text="audio message.", accumulated="I received your audio message."),
            session_id
        )
        await self.send_message(
            ResponseCompleteMessage(
                text="I received your audio message.",
                audio_url="/voice/audio/placeholder.wav"
            ),
            session_id
        )
        
        # Clear buffer
        self.audio_buffers[session_id] = bytearray()

    async def _process_text(self, session_id: str, text: str):
        """Process text input and generate response."""
        logger.info(f"Processing text: {text[:50]}...")
        
        # TODO: Implement streaming response
        # For now, send placeholder
        await self.send_message(
            ResponseChunkMessage(text="Processing ", accumulated="Processing "),
            session_id
        )
        await self.send_message(
            ResponseChunkMessage(text="your message...", accumulated="Processing your message..."),
            session_id
        )
        await self.send_message(
            ResponseCompleteMessage(
                text="Processing your message...",
                audio_url="/voice/audio/placeholder.wav"
            ),
            session_id
        )


# Singleton instance
websocket_manager = WebSocketManager()


# =============================================================================
# WebSocket Route
# =============================================================================

async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for voice streaming.
    
    Protocol:
    1. Client connects
    2. Server sends {"type": "ready", "session_id": "..."}
    3. Client sends JSON messages or binary audio chunks
    4. Server streams responses back
    """
    session_id = "voice"  # TODO: Support multiple sessions
    
    await websocket_manager.connect(websocket, session_id)
    
    try:
        while True:
            # Use receive() to handle both text and binary
            message = await websocket.receive()
            
            if message["type"] == "websocket.receive":
                if "text" in message:
                    # JSON message
                    import json
                    data = json.loads(message["text"])
                    await websocket_manager.handle_json_message(websocket, session_id, data)
                elif "bytes" in message:
                    # Binary audio chunk
                    await websocket_manager.handle_binary(websocket, session_id, message["bytes"])
                    
            elif message["type"] == "websocket.disconnect":
                break
                
    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected: {session_id}")
    except Exception as e:
        logger.exception(f"WebSocket error: {e}")
    finally:
        await websocket_manager.disconnect(session_id)


def register_websocket_routes(app: FastAPI):
    """Register WebSocket routes with the FastAPI app."""
    app.websocket("/voice/stream")(websocket_endpoint)
    logger.info("Registered WebSocket route: /voice/stream")
