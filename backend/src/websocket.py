"""
WebSocket handler for voice streaming API.
Generated by qwen2.5-coder:32b, refined by GLaDOS.
"""

import asyncio
import logging
from typing import Dict, Optional, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from starlette.websockets import WebSocketState

from .transcribe import ChunkedTranscriber
from .stream_response import stream_chat_response
from .main import strip_markdown

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


# =============================================================================
# Message Types (Client → Server)
# =============================================================================

class AudioStartMessage(BaseModel):
    type: str = "audio_start"
    format: str  # webm, wav, mp4


class AudioEndMessage(BaseModel):
    type: str = "audio_end"


class TextMessage(BaseModel):
    type: str = "text"
    content: str


class CancelMessage(BaseModel):
    type: str = "cancel"


# =============================================================================
# Message Types (Server → Client)
# =============================================================================

class ReadyMessage(BaseModel):
    type: str = "ready"
    session_id: str


class PartialTranscriptMessage(BaseModel):
    type: str = "partial_transcript"
    text: str
    is_final: bool = False


class FinalTranscriptMessage(BaseModel):
    type: str = "final_transcript"
    text: str


class ResponseChunkMessage(BaseModel):
    type: str = "response_chunk"
    text: str
    accumulated: str


class ResponseCompleteMessage(BaseModel):
    type: str = "response_complete"
    text: str
    audio_url: str


class ErrorMessage(BaseModel):
    type: str = "error"
    code: str
    message: str


# =============================================================================
# WebSocket Manager
# =============================================================================

class WebSocketManager:
    """Manages WebSocket connections and message routing."""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.audio_buffers: Dict[str, bytearray] = {}
        self.audio_formats: Dict[str, str] = {}
        self.transcribers: Dict[str, ChunkedTranscriber] = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        """Accept connection and send ready message."""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        self.audio_buffers[session_id] = bytearray()
        self.transcribers[session_id] = ChunkedTranscriber(
            chunk_duration_ms=3000,
            overlap_ms=500,
            model="base"
        )
        
        ready_message = ReadyMessage(session_id=session_id)
        await websocket.send_json(ready_message.dict())
        logger.info(f"Client connected: {session_id}")

    async def disconnect(self, session_id: str):
        """Clean up connection state."""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
        if session_id in self.audio_buffers:
            del self.audio_buffers[session_id]
        if session_id in self.audio_formats:
            del self.audio_formats[session_id]
        if session_id in self.transcribers:
            del self.transcribers[session_id]
        logger.info(f"Client disconnected: {session_id}")

    async def send_message(self, message: BaseModel, session_id: str):
        """Send a message to a specific session."""
        if session_id in self.active_connections:
            ws = self.active_connections[session_id]
            if ws.client_state == WebSocketState.CONNECTED:
                await ws.send_json(message.dict())

    async def handle_json_message(self, websocket: WebSocket, session_id: str, data: Dict[str, Any]):
        """Route JSON messages to appropriate handlers."""
        msg_type = data.get("type")
        
        try:
            if msg_type == "audio_start":
                audio_start = AudioStartMessage(**data)
                self.audio_formats[session_id] = audio_start.format
                self.audio_buffers[session_id] = bytearray()
                # Configure transcriber for this format
                if session_id in self.transcribers:
                    self.transcribers[session_id].set_format(audio_start.format)
                    self.transcribers[session_id].reset()
                logger.debug(f"Audio start: format={audio_start.format}")
                
            elif msg_type == "audio_end":
                logger.debug(f"Audio end: {len(self.audio_buffers.get(session_id, []))} bytes buffered")
                await self._process_audio(session_id)
                
            elif msg_type == "text":
                text_msg = TextMessage(**data)
                logger.debug(f"Text received: {text_msg.content[:50]}...")
                await self._process_text(session_id, text_msg.content)
                
            elif msg_type == "cancel":
                logger.debug(f"Cancel received for {session_id}")
                # TODO: Cancel any in-progress transcription/response
                self.audio_buffers[session_id] = bytearray()
                
            else:
                logger.warning(f"Unknown message type: {msg_type}")
                await self.send_message(
                    ErrorMessage(code="unknown_type", message=f"Unknown message type: {msg_type}"),
                    session_id
                )
                
        except Exception as e:
            logger.exception(f"Error handling message: {e}")
            await self.send_message(
                ErrorMessage(code="message_error", message=str(e)),
                session_id
            )

    async def handle_binary(self, websocket: WebSocket, session_id: str, data: bytes):
        """Buffer incoming audio chunks."""
        if session_id in self.audio_buffers:
            self.audio_buffers[session_id].extend(data)
            logger.debug(f"Audio chunk: {len(data)} bytes (total: {len(self.audio_buffers[session_id])})")
        else:
            logger.warning(f"Received binary data without audio_start for {session_id}")

    async def _process_audio(self, session_id: str):
        """Process buffered audio - transcribe and generate response."""
        audio_data = bytes(self.audio_buffers.get(session_id, b""))
        audio_format = self.audio_formats.get(session_id, "webm")
        
        if not audio_data:
            await self.send_message(
                ErrorMessage(code="no_audio", message="No audio data received"),
                session_id
            )
            return

        logger.info(f"Processing {len(audio_data)} bytes of {audio_format} audio")
        
        # Get or create transcriber
        transcriber = self.transcribers.get(session_id)
        if not transcriber:
            transcriber = ChunkedTranscriber()
            transcriber.set_format(audio_format)
            self.transcribers[session_id] = transcriber
        
        # Send partial transcript notification
        await self.send_message(
            PartialTranscriptMessage(text="Transcribing...", is_final=False),
            session_id
        )
        
        # Feed all buffered audio to transcriber and finalize
        logger.info(f"Setting transcriber buffer with {len(audio_data)} bytes")
        transcriber.audio_buffer = bytearray(audio_data)
        logger.info(f"Transcriber buffer size: {len(transcriber.audio_buffer)} bytes")
        transcript = await transcriber.finalize()
        
        if not transcript:
            transcript = "[Could not transcribe audio]"
            
        logger.info(f"Transcribed: {transcript[:100]}...")
        
        # Send final transcript
        await self.send_message(
            FinalTranscriptMessage(text=transcript),
            session_id
        )
        
        # Process the transcript through chat
        await self._process_text(session_id, transcript)
        
        # Clear buffer
        self.audio_buffers[session_id] = bytearray()

    async def _process_text(self, session_id: str, text: str):
        """Process text input and generate response via OpenClaw."""
        logger.info(f"Processing text: {text[:50]}...")
        
        accumulated = ""
        
        try:
            # Stream response chunks from OpenClaw
            async for chunk in stream_chat_response(text, session_id="voice"):
                accumulated += (" " if accumulated else "") + chunk
                
                await self.send_message(
                    ResponseChunkMessage(text=chunk, accumulated=accumulated),
                    session_id
                )
            
            # Generate TTS for the response
            audio_url = await self._generate_tts(accumulated)
            logger.info(f"Generated TTS audio_url: {audio_url}")
            
            await self.send_message(
                ResponseCompleteMessage(
                    text=accumulated,
                    audio_url=audio_url
                ),
                session_id
            )
            logger.info(f"Sent response_complete with audio_url: {audio_url}")
            
        except Exception as e:
            logger.exception(f"Error processing text: {e}")
            await self.send_message(
                ErrorMessage(code="processing_error", message=str(e)),
                session_id
            )

    async def _generate_tts(self, text: str) -> str:
        """Generate TTS audio for response text."""
        import uuid
        from pathlib import Path
        
        # Use the existing TTS setup from main.py
        audio_id = uuid.uuid4().hex
        output_dir = Path("audio_cache")
        output_dir.mkdir(exist_ok=True)
        output_file = output_dir / f"{audio_id}.wav"
        
        # Strip markdown and escape text for shell
        clean_text = strip_markdown(text)
        safe_text = clean_text.replace('"', '\\"').replace("'", "'\\''")
        
        # Piper TTS command
        piper_cmd = f'eval "$(pyenv init -)" && echo "{safe_text}" | piper -m /Users/rich/Projects/piper-models/en_US-lessac-medium.onnx -f {output_file}'
        
        try:
            process = await asyncio.create_subprocess_shell(
                piper_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            await asyncio.wait_for(process.communicate(), timeout=30)
            
            if output_file.exists():
                return f"/voice/audio/{audio_id}.wav"
            else:
                logger.error("Piper did not produce output file")
                return "/voice/audio/error.wav"
                
        except Exception as e:
            logger.exception(f"TTS error: {e}")
            return "/voice/audio/error.wav"


# Singleton instance
websocket_manager = WebSocketManager()


# =============================================================================
# WebSocket Route
# =============================================================================

async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for voice streaming.
    
    Protocol:
    1. Client connects
    2. Server sends {"type": "ready", "session_id": "..."}
    3. Client sends JSON messages or binary audio chunks
    4. Server streams responses back
    """
    session_id = "voice"  # TODO: Support multiple sessions
    
    await websocket_manager.connect(websocket, session_id)
    
    try:
        while True:
            # Use receive() to handle both text and binary
            message = await websocket.receive()
            
            if message["type"] == "websocket.receive":
                if "text" in message:
                    # JSON message
                    import json
                    data = json.loads(message["text"])
                    await websocket_manager.handle_json_message(websocket, session_id, data)
                elif "bytes" in message:
                    # Binary audio chunk
                    await websocket_manager.handle_binary(websocket, session_id, message["bytes"])
                    
            elif message["type"] == "websocket.disconnect":
                break
                
    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected: {session_id}")
    except Exception as e:
        logger.exception(f"WebSocket error: {e}")
    finally:
        await websocket_manager.disconnect(session_id)


def register_websocket_routes(app: FastAPI):
    """Register WebSocket routes with the FastAPI app."""
    app.websocket("/voice/stream")(websocket_endpoint)
    logger.info("Registered WebSocket route: /voice/stream")
