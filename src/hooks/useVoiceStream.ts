/**
 * WebSocket-based voice streaming hook.
 * Generated by qwen2.5-coder:32b, refined by GLaDOS.
 */

import { useState, useEffect, useCallback, useRef } from 'react';

export interface UseVoiceStreamReturn {
  status: 'disconnected' | 'connecting' | 'ready' | 'recording' | 'processing';
  partialTranscript: string;
  finalTranscript: string;
  responseText: string;
  responseComplete: boolean;
  audioQueue: string[];
  error: string | null;
  connect: () => void;
  disconnect: () => void;
  startRecording: () => Promise<void>;
  stopRecording: () => void;
  sendText: (text: string) => void;
  cancel: () => void;
  clearResponse: () => void;
}

const RECONNECT_DELAYS = [1000, 2000, 5000, 10000];

export function useVoiceStream(wsUrl: string): UseVoiceStreamReturn {
  const [status, setStatus] = useState<UseVoiceStreamReturn['status']>('disconnected');
  const [partialTranscript, setPartialTranscript] = useState('');
  const [finalTranscript, setFinalTranscript] = useState('');
  const [responseText, setResponseText] = useState('');
  const [responseComplete, setResponseComplete] = useState(false);
  const [audioQueue, setAudioQueue] = useState<string[]>([]);
  const [error, setError] = useState<string | null>(null);

  const wsRef = useRef<WebSocket | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const reconnectDelayIndexRef = useRef(0);
  const shouldReconnectRef = useRef(true);

  const connect = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) return;
    
    shouldReconnectRef.current = true;
    setStatus('connecting');
    setError(null);

    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      reconnectDelayIndexRef.current = 0;
      // Don't set ready here - wait for 'ready' message from server
    };

    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        
        switch (data.type) {
          case 'ready':
            setStatus('ready');
            break;
            
          case 'partial_transcript':
            setPartialTranscript(data.text);
            break;
            
          case 'final_transcript':
            setFinalTranscript(data.text);
            setPartialTranscript('');
            break;
            
          case 'response_chunk':
            setResponseText(data.accumulated || (prev => prev + data.text));
            setStatus('processing');
            break;
            
          case 'response_complete':
            setResponseText(data.text);
            setResponseComplete(true);
            if (data.audio_url) {
              setAudioQueue(prev => [...prev, data.audio_url]);
            }
            setStatus('ready');
            break;
            
          case 'error':
            setError(data.message || 'Unknown error');
            break;
        }
      } catch (e) {
        console.error('Failed to parse WebSocket message:', e);
      }
    };

    ws.onclose = () => {
      wsRef.current = null;
      
      if (shouldReconnectRef.current) {
        const delay = RECONNECT_DELAYS[Math.min(reconnectDelayIndexRef.current, RECONNECT_DELAYS.length - 1)];
        reconnectDelayIndexRef.current++;
        
        setTimeout(() => {
          if (shouldReconnectRef.current) {
            connect();
          }
        }, delay);
      } else {
        setStatus('disconnected');
      }
    };

    ws.onerror = (event) => {
      console.error('WebSocket error:', event);
      setError('WebSocket connection error');
    };
  }, [wsUrl]);

  const disconnect = useCallback(() => {
    shouldReconnectRef.current = false;
    
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    
    setStatus('disconnected');
  }, []);

  const startRecording = useCallback(async () => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      setError('WebSocket not connected');
      return;
    }
    
    if (status !== 'ready') return;

    try {
      // Get microphone access
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      // Determine best supported format
      let mimeType = 'audio/webm';
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
        mimeType = 'audio/mp4'; // Safari fallback
      }

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;

      // Send audio_start message
      wsRef.current.send(JSON.stringify({ 
        type: 'audio_start', 
        format: mimeType.split('/')[1].split(';')[0] // 'webm' or 'mp4'
      }));

      // Stream audio chunks to server
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && wsRef.current?.readyState === WebSocket.OPEN) {
          wsRef.current.send(event.data);
        }
      };

      mediaRecorder.onerror = (e) => {
        console.error('MediaRecorder error:', e);
        setError('Recording failed');
        setStatus('ready');
      };

      // Start recording with 250ms chunks
      mediaRecorder.start(250);
      setStatus('recording');
      
      // Clear previous response
      setResponseText('');
      setResponseComplete(false);
      setPartialTranscript('');
      setFinalTranscript('');

    } catch (err) {
      const message = err instanceof Error ? err.message : 'Failed to start recording';
      setError(message);
      console.error('Recording error:', err);
    }
  }, [status]);

  const stopRecording = useCallback(() => {
    if (!mediaRecorderRef.current) return;

    if (mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    // Stop all tracks
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    // Send audio_end message
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'audio_end' }));
    }

    mediaRecorderRef.current = null;
    setStatus('processing');
  }, []);

  const sendText = useCallback((text: string) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      setError('WebSocket not connected');
      return;
    }
    
    if (status !== 'ready') return;

    wsRef.current.send(JSON.stringify({ type: 'text', content: text }));
    setStatus('processing');
    
    // Clear previous response
    setResponseText('');
    setResponseComplete(false);
  }, [status]);

  const cancel = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'cancel' }));
    }

    // Stop recording if active
    if (mediaRecorderRef.current?.state !== 'inactive') {
      mediaRecorderRef.current?.stop();
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    setPartialTranscript('');
    setFinalTranscript('');
    setResponseText('');
    setResponseComplete(false);
    setStatus('ready');
  }, []);

  const clearResponse = useCallback(() => {
    setResponseText('');
    setResponseComplete(false);
    setAudioQueue([]);
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      shouldReconnectRef.current = false;
      
      if (wsRef.current) {
        wsRef.current.close();
      }
      
      if (mediaRecorderRef.current?.state !== 'inactive') {
        mediaRecorderRef.current?.stop();
      }
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  return {
    status,
    partialTranscript,
    finalTranscript,
    responseText,
    responseComplete,
    audioQueue,
    error,
    connect,
    disconnect,
    startRecording,
    stopRecording,
    sendText,
    cancel,
    clearResponse,
  };
}
